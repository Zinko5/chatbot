# Ficha TÃ©cnica â€“ **El Deber Bot**

---

## 1ï¸âƒ£ VisiÃ³n General del Proyecto

**El Deber Bot** es un agente conversacional especializado en noticias del portal boliviano *eldeber.com.bo*.  Combina varias capas de procesamiento:

1. **Scraper robusto** que extrae titulares y contenidos de mÃºltiples secciones.
2. **AnÃ¡lisis de sentimientos hÃ­brido** (palabrasâ€‘clave bolivianas + modelo BERT multilingual).
3. **GeneraciÃ³n de embeddings** con *Sentenceâ€‘Transformer* para bÃºsqueda semÃ¡ntica.
4. **Motor de IA** basado en la API de **Groq** (modelo `llamaâ€‘3.1â€‘8bâ€‘instant`).
5. **Interfaz web** (Flask) y **bot de Telegram** que exponen la funcionalidad al usuario.

Todo el flujo estÃ¡ orquestado por la clase `NewsChatBot` que se inicializa en segundo plano para que la UI sea responsiva.

---

## 2ï¸âƒ£ Arquitectura de Componentes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Telegram Bot       â”‚          â”‚  Flask Web UI       â”‚
â”‚  (telegram_bot.py) â”‚  <--->   â”‚  (app.py)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                               â”‚
          â”‚   Shared global DATA_STORE    â”‚
          â”‚   (config.py)                â”‚
          â–¼                               â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  NewsChatBot        â”‚   â”‚  Sentiment Engine   â”‚
   â”‚  (chatbot.py)      â”‚   â”‚  (sentiment.py)    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                         â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Scraper            â”‚   â”‚  Embeddings Engine  â”‚
   â”‚  (scraper.py)       â”‚   â”‚  (brain.py)        â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

* **DATA_STORE** â€“ diccionario global que mantiene el estado compartido (titulares, progreso, flags de inicializaciÃ³n, etc.).
* Cada componente es **threadâ€‘safe** porque se accede Ãºnicamente desde el hilo de inicializaciÃ³n o desde peticiones HTTP/Telegram que solo leen.

---

## 3ï¸âƒ£ ConfiguraciÃ³n y Variables de Entorno

| Variable | DescripciÃ³n | Fuente |
|----------|-------------|--------|
| `GROQ_API_KEY` | APIâ€‘key para la plataforma Groq. | `.env` (cargado con `dotenv`)
| `TELEGRAM_BOT_TOKEN` | Token del bot de Telegram. | `.env`
| `SECCIONES_CONFIG` | Mapeo *URL â†’ nÃºmero de pÃ¡ginas* a rastrear. | `config.py`
| `HEADERS` | Cabecera HTTP para evitar bloqueos de scraper. | `config.py`
| `EMBEDDING_MODEL` | Modelo Sentenceâ€‘Transformer usado para embeddings. | `config.py`
| `DATA_STORE` | Estructura global de estado (titulares, progreso, flags). | `config.py`

---

## 4ï¸âƒ£ Scraper â€“ `scraper.py`

### 4.1 SesiÃ³n HTTP Resistente
* **`crear_sesion()`** crea una `requests.Session` con `urllib3.Retry` (3 intentos, backâ€‘off exponencial, cÃ³digos 429/5xx).
* Cabecera `Userâ€‘Agent` configurable en `HEADERS`.

### 4.2 ExtracciÃ³n de Contenido
* `extraer_contenido_noticia(url)`:
  * Pausa aleatoria `0.1â€‘0.5â€¯s` para respetar el sitio.
  * Busca varios selectores (`text-editor`, `nota-body`, â€¦) y, como fallback, cualquier `<article>`.
  * Filtra pÃ¡rrafos menores a 30â€¯caracteres y elimina frases â€œLee tambiÃ©nâ€.
  * Limita a 1500â€¯caracteres para no superar el contexto de LLM.

### 4.3 Procesado de ArtÃ­culos
* `procesar_articulo(art)` extrae tÃ­tulo, URL y contenido, normaliza enlaces relativos.
* Devuelve `None` si falla; los errores se capturan y no interrumpen el flujo.

### 4.4 Paralelismo
* `ThreadPoolExecutor(max_workers=4)` procesa artÃ­culos de una pÃ¡gina en paralelo.
* `extraer_titulares_pagina` y `extraer_todas_las_noticias` usan `max_workers=2` para paralelizar la descarga de pÃ¡ginas por secciÃ³n.

### 4.5 Progreso y MÃ©tricas
* `DATA_STORE['progress']` se actualiza en tiempo real (0â€‘45â€¯% durante scraping).
* `DATA_STORE['titulares']` acumula resultados y se comparte con la UI.

---

## 5ï¸âƒ£ AnÃ¡lisis de Sentimientos â€“ `sentiment.py`

### 5.1 Modelo BERT MultilingÃ¼e
* Cargado con `pipeline('sentiment-analysis', model='nlptown/bert-base-multilingual-uncased-sentiment')`.
* Ejecutado en CPU (`device=-1`).

### 5.2 Diccionarios de Palabrasâ€‘Clave Bolivianas
* **Negativas** (â‰ˆâ€¯30 tÃ©rminos) y **Positivas** (â‰ˆâ€¯30 tÃ©rminos) enfocadas a la realidad local (p.ej., *tragedia*, *ganÃ³*).
* Prioridad **mÃ¡xima**: si se detecta cualquier tÃ©rmino negativo, la noticia se clasifica como **Negativo** sin consultar BERT.

### 5.3 FunciÃ³n Principal
* `analizar_sentimiento_noticia(texto) â†’ (emocion, color, nivel, descripcion)`
  * Busca coincidencias de palabrasâ€‘clave usando expresiones regulares con lÃ­mites de palabra (`\b`).
  * Si no hay coincidencias, recurre al modelo BERT (estrella 1â€‘2 â†’ Negativo, 3 â†’ Neutral, 4â€‘5 â†’ Positivo).
  * Nivel de confianza: **Alto** (>â€¯0.7), **Medio** (â‰¤â€¯0.7), **Bajo** (error).
  * Devuelve tambiÃ©n el color hex asociado (`COLORES`).

### 5.4 Enriquecimiento de Noticias
* `enriquecer_noticias_con_sentimientos(noticias)` recorre la lista, combina tÃ­tulo + contenido y aÃ±ade los campos:
  * `sentimiento`, `color_sentimiento`, `nivel_sentimiento`, `descripcion_sentimiento`.
* Actualiza `DATA_STORE['noticias_analizadas']` para que la UI muestre progreso (0â€‘65â€¯% del flujo total).

### 5.5 EstadÃ­sticas y BÃºsqueda por Sentimiento
* `mostrar_estadisticas_sentimientos` imprime barras de progreso en consola.
* Funciones `buscar_noticias_positivas/negativas/neutrales` filtran la lista.
* `detectar_consulta_sentimiento(pregunta)` reconoce si el usuario pide â€œnoticias positivasâ€, etc., para redirigir la lÃ³gica en `chatbot.answer`.

---

## 6ï¸âƒ£ Embeddings y BÃºsqueda SemÃ¡ntica â€“ `brain.py`

### 6.1 Modelo de Embeddings
* `SentenceTransformer(EMBEDDING_MODEL)` donde `EMBEDDING_MODEL = "paraphrase-multilingual-MiniLM-L12-v2"`.
* Cargado una sola vez (singleton) para evitar recargas costosas.

### 6.2 Indexado
* `SemanticSearch.index_documents(documents)` genera embeddings de la concatenaciÃ³n `"{titulo}. {resumen}"`.
* Se muestra barra de progreso (`show_progress_bar=True`).

### 6.3 BÃºsqueda HÃ­brida
* **SemÃ¡ntica**: encode la query (y su versiÃ³n titleâ€‘cased) y calcula similitud coseno contra todos los embeddings.
* **Keyword Boosting**: si la query aparece literalmente en tÃ­tulo o resumen, se suma **0.3** al score.
* **Ranking**: topâ€‘k (defaultâ€¯3) con umbral 0.12 (mÃ¡s permisivo gracias al boost).
* Resultado incluye `score` y los campos originales de la noticia.

---

## 7ï¸âƒ£ Motor de IA â€“ Groq (`brain.GroqBrain`)

* ConexiÃ³n segura mediante `GROQ_API_KEY`.
* Modelo por defecto: `llama-3.1-8b-instant`.
* **Prompt system**: instrucciones estrictas para que el modelo solo use la informaciÃ³n de las noticias y no invente datos.
* **Fallback** (`_basic_response`) genera una respuesta estÃ¡tica cuando Groq no estÃ¡ configurado.
* ParÃ¡metros de generaciÃ³n: `temperature=0.3`, `max_tokens=500`.

---

## 8ï¸âƒ£ Bot de Telegram â€“ `telegram_bot.py`

* Usa `pythonâ€‘telegramâ€‘bot` (versiÃ³n implÃ­cita en `requirements.txt`).
* **Handlers** principales:
  * `/start` â€“ saludo y breve descripciÃ³n.
  * Mensajes de texto â€“ delega a `bot.answer` y envÃ­a la respuesta.
* El bot se inicia **en un thread** separado desde `app.py` para que Flask y Telegram coexistan.
* Manejo de estados: si el bot estÃ¡ todavÃ­a inicializando, responde con `â³ El bot se estÃ¡ inicializandoâ€¦`.

---

## 9ï¸âƒ£ AplicaciÃ³n Web â€“ `app.py`

* Flask app que sirve los templates bajo `templates/` (no mostrados aquÃ­).
* Ruta principal `/` renderiza la UI que muestra:
  * Barra de progreso (`DATA_STORE['progress']`).
  * Lista de titulares (`DATA_STORE['titulares']`).
  * EstadÃ­sticas de sentimientos.
* Al iniciar, llama a `bot.initialize_async()` para lanzar la inicializaciÃ³n en background.
* El servidor se ejecuta con `python3 app.py` (modo desarrollo) y estÃ¡ preparado para `npm run dev` solo si se migra a Vite (no usado actualmente).

---

## ğŸ”§ Dependencias â€“ `requirements.txt`
```
flask
python-telegram-bot
requests
beautifulsoup4
urllib3
sentence-transformers
scikit-learn
groq
transformers
torch   # required by transformers (CPU only)
python-dotenv
```
> Todas las librerÃ­as son **CPUâ€‘only**; el proyecto estÃ¡ pensado para ejecutarse en una mÃ¡quina con Pythonâ€¯3.10+.

---

## ğŸš€ Puesta en Marcha
1. **Clonar** el repositorio.
2. Crear entorno virtual y activar:
   ```bash
   python -m venv venv
   source venv/bin/activate
   ```
3. Instalar dependencias:
   ```bash
   pip install -r requirements.txt
   ```
4. Copiar y rellenar `.env`:
   ```bash
   cp .env.example .env
   # editar .env y aÃ±adir GROQ_API_KEY y TELEGRAM_BOT_TOKEN
   ```
5. Ejecutar la aplicaciÃ³n:
   ```bash
   python3 app.py
   ```
   * El bot tarda **entre 2 y 5â€¯min** en completarse (scrapingâ€¯+â€¯sentimientosâ€¯+â€¯carga de modelos).
   * Acceder a `http://127.0.0.1:5000` para la UI web.
   * Interactuar con el bot de Telegram usando el token configurado.

---

## ğŸ“š Extensibilidad
| Ãrea | QuÃ© se puede ampliar |
|------|----------------------|
| **Scraper** | AÃ±adir nuevas secciones en `SECCIONES_CONFIG`; incrementar `max_workers` para mayor paralelismo.
| **Sentimientos** | Ampliar los diccionarios de palabrasâ€‘clave o cambiar el modelo BERT por uno mÃ¡s grande.
| **Embeddings** | Sustituir `EMBEDDING_MODEL` por un modelo especializado en noticias.
| **IA** | Cambiar a otro modelo Groq o a OpenAI/Claude simplemente modificando `GroqBrain`.
| **UI** | Migrar a Vite/Next.js para una SPA mÃ¡s moderna (manteniendo la API Flask).

---

## ğŸ›¡ï¸ Seguridad y Buenas PrÃ¡cticas
* **API keys** nunca se versionan; se cargan desde `.env`.
* Scraper respeta `robots.txt` implÃ­citamente mediante pausas aleatorias y nÃºmero limitado de peticiones concurrentes.
* Todos los accesos a `DATA_STORE` son de solo lectura desde la UI; la escritura ocurre Ãºnicamente en el hilo de inicializaciÃ³n.
* El bot de Telegram valida que el mensaje no sea demasiado largo antes de enviarlo a Groq (limite 500â€¯tokens).

---

## ğŸ“Œ Resumen rÃ¡pido para mantenedores
* **InicializaciÃ³n** â†’ Scraping (0â€‘45â€¯%) â†’ Sentimientos (45â€‘65â€¯%) â†’ Carga de modelos (65â€‘78â€¯%) â†’ Embeddings (78â€‘90â€¯%) â†’ Final (90â€‘100â€¯%).
* **Estado global** â†’ `DATA_STORE` (titulares, progreso, flags).
* **Puntos crÃ­ticos** â†’ ConexiÃ³n a Groq (requiere API key vÃ¡lida) y disponibilidad del sitio `eldeber.com.bo`.
* **Tiempo de arranque** â†’ 2â€‘5â€¯min (dependiendo de la velocidad de red).

---

*Ficha tÃ©cnica generada automÃ¡ticamente por Antigravity â€“ agente de codificaciÃ³n avanzada.*
