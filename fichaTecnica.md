# üìò Ficha T√©cnica Maestra: El Deber Bot

> **Versi√≥n del Documento**: 1.0
> **Fecha de Generaci√≥n**: Noviembre 2024
> **Prop√≥sito**: Documentaci√≥n t√©cnica exhaustiva para desarrolladores y mantenedores.

---

## 1. üåü Visi√≥n General del Proyecto
**El Deber Bot** es un sistema de Inteligencia Artificial conversacional dise√±ado para democratizar el acceso a la informaci√≥n period√≠stica de Bolivia. Funciona como un asistente virtual que "lee" en tiempo real las noticias del diario *El Deber* y responde preguntas de los usuarios bas√°ndose estrictamente en esa informaci√≥n.

El sistema implementa una arquitectura **RAG (Retrieval-Augmented Generation)**, combinando la precisi√≥n de b√∫squeda de informaci√≥n actualizada con la capacidad de s√≠ntesis y lenguaje natural de los Modelos de Lenguaje Grande (LLMs).

### Capacidades Principales
*   **Scraping en Tiempo Real**: Monitoreo activo de m√∫ltiples secciones de noticias.
*   **B√∫squeda Sem√°ntica**: Entendimiento del significado de las preguntas, no solo palabras clave.
*   **S√≠ntesis Inteligente**: Generaci√≥n de respuestas coherentes citando fuentes.
*   **Interfaz Reactiva**: UI moderna con feedback visual de procesos en segundo plano.

---

## 2. üõ†Ô∏è Stack Tecnol√≥gico

### Backend & Core
| Tecnolog√≠a | Versi√≥n | Prop√≥sito |
| :--- | :--- | :--- |
| **Python** | 3.10+ | Lenguaje base del servidor y l√≥gica de IA. |
| **Flask** | 3.0.0 | Micro-framework web para servir la API y el Frontend. |
| **Werkzeug** | 3.0.1 | Utilidades WSGI subyacentes a Flask. |

### Inteligencia Artificial (AI/ML)
| Librer√≠a/Servicio | Modelo/Versi√≥n | Funci√≥n |
| :--- | :--- | :--- |
| **Groq API** | `llama-3.1-8b-instant` | **Cerebro Generativo**. Procesa el contexto y genera la respuesta final a velocidad extrema. |
| **Sentence-Transformers** | `paraphrase-multilingual-MiniLM-L12-v2` | **Motor de Embeddings**. Convierte texto a vectores (384 dimensiones) para b√∫squeda sem√°ntica. |
| **Scikit-learn** | 1.3.2 | C√°lculo de **Similitud Coseno** para ranking de relevancia. |
| **Numpy** | 1.24.3 | Operaciones matem√°ticas vectoriales de alto rendimiento. |
| **PyTorch** | 2.1.0 | Backend de c√≥mputo para los transformers. |

### Web Scraping & Datos
| Herramienta | Prop√≥sito |
| :--- | :--- |
| **Requests** | Cliente HTTP con estrategia de reintentos (Retry Strategy) para robustez ante fallos de red. |
| **BeautifulSoup4** | Parser HTML (con `lxml`) para extracci√≥n precisa de contenido del DOM. |
| **ThreadPoolExecutor** | Concurrencia para procesar m√∫ltiples p√°ginas de noticias simult√°neamente. |

### Frontend
*   **HTML5 / CSS3**: Dise√±o moderno con variables CSS, Glassmorphism y animaciones.
*   **Vanilla JavaScript**: L√≥gica de cliente ligera (Fetch API, DOM manipulation) sin frameworks pesados.
*   **Jinja2**: Motor de plantillas (usado m√≠nimamente para inyecci√≥n inicial de estado).

---

## 3. üèóÔ∏è Arquitectura del Sistema

El sistema sigue un patr√≥n modular donde cada componente tiene una responsabilidad √∫nica.

### Diagrama de Flujo de Datos
```mermaid
graph TD
    User[Usuario] -->|Pregunta| API[Flask API]
    
    subgraph "Fase 1: Ingesta (Background)"
        Web[El Deber] -->|Scraping| Scraper[Scraper.py]
        Scraper -->|Texto Limpio| Embedder[Sentence Transformer]
        Embedder -->|Vectores| VectorDB[(Memoria RAM)]
    end
    
    subgraph "Fase 2: Retrieval (B√∫squeda)"
        API -->|Query| Search[Semantic Search]
        Search -->|Query Vector| Embedder
        VectorDB -->|Comparaci√≥n| Search
        Search -->|Top-K Noticias| Contexto
    end
    
    subgraph "Fase 3: Generaci√≥n"
        Contexto -->|Prompt| Brain[Groq Brain]
        Brain -->|Llama 3| Response[Respuesta Generada]
    end
    
    Response -->|JSON| API
    API -->|HTML/Text| User
```

---

## 4. üìÇ Estructura de Archivos y Componentes

### `app.py` (Controlador Principal)
Es el punto de entrada. Configura el servidor Flask y define las rutas.
*   **Rutas Clave**:
    *   `GET /`: Sirve la interfaz de usuario.
    *   `POST /api/chat`: Endpoint principal de consulta. Recibe JSON `{'question': '...'}`.
    *   `GET /api/status`: Long-polling para barra de progreso y estado del bot.
    *   `POST /api/toggle-groq`: Switch para activar/desactivar el uso de LLM externo.

### `chatbot.py` (Orquestador)
Clase `NewsChatBot`. Act√∫a como fachada (Facade Pattern) que coordina los subsistemas.
*   **Responsabilidad**: Inicializaci√≥n as√≠ncrona (threading) para no bloquear el arranque del servidor.
*   **M√©todo `answer()`**: Coordina la b√∫squeda + generaci√≥n. Maneja casos de error y fallbacks.

### `brain.py` (L√≥gica de IA)
Contiene dos clases cr√≠ticas:
1.  **`SemanticSearch` (Singleton)**:
    *   Carga el modelo `MiniLM-L12`.
    *   **Indexaci√≥n**: `index_documents()` convierte noticias a vectores.
    *   **B√∫squeda H√≠brida**: Implementa un algoritmo propio que combina similitud sem√°ntica pura con *Keyword Boosting* (bonificaci√≥n de puntaje si palabras clave exactas aparecen en el texto).
2.  **`GroqBrain`**:
    *   Wrapper para la API de Groq.
    *   Construye el *System Prompt* que instruye al modelo a ser un "asistente de noticias bolivianas" y a no alucinar informaci√≥n.

### `scraper.py` (Motor de Extracci√≥n)
Sistema robusto de extracci√≥n de datos.
*   **Sesi√≥n Persistente**: Usa `requests.Session()` con adaptadores HTTP para reutilizar conexiones TCP.
*   **Estrategia de Reintentos**: Configurado para reintentar autom√°ticamente en errores 5xx o 429 (Rate Limits).
*   **Paralelismo**: Usa `ThreadPoolExecutor` para descargar m√∫ltiples p√°ginas de noticias a la vez, reduciendo el tiempo de carga.
*   **Selectores Inteligentes**: Lista de selectores CSS de respaldo (`fallback`) por si el dise√±o de la web cambia.

### `templates.py` (Frontend)
Contiene la variable `HTML_TEMPLATE` que es una *Single File Component* gigante.
*   Incluye todo el HTML, CSS (estilos glassmorphism, animaciones de carga) y JavaScript del cliente.
*   Maneja la l√≥gica de UI: Chat, barra de progreso, toggle de Groq, sugerencias.

### `config.py` (Configuraci√≥n)
Centraliza constantes y variables de entorno.
*   `SECCIONES_CONFIG`: Diccionario que define qu√© URLs rastrear y cu√°ntas p√°ginas de profundidad.
*   `DATA_STORE`: Almac√©n en memoria (diccionario global) compartido entre hilos para guardar las noticias y el estado.

---

## 5. üîÑ Workflow Detallado

### A. Inicializaci√≥n (Boot Sequence)
1.  Al ejecutar `python app.py`, Flask arranca inmediatamente.
2.  Se llama a `bot.initialize_async()`, que lanza un hilo demonio (daemon thread).
3.  **En el hilo secundario**:
    *   Se limpian las variables globales.
    *   Se ejecuta el scraping masivo.
    *   Se carga el modelo de embeddings en memoria (pesado).
    *   Se generan los vectores de todas las noticias descargadas.
    *   Se marca `initialized = True`.

### B. Ciclo de Vida de una Pregunta (Request Lifecycle)
1.  **Recepci√≥n**: Usuario env√≠a "¬øQu√© pas√≥ con el censo?".
2.  **Validaci√≥n**: Se verifica que el bot est√© inicializado y la pregunta no est√© vac√≠a.
3.  **Embedding**: La pregunta se vectoriza usando `SentenceTransformer`.
4.  **Retrieval (Recuperaci√≥n)**:
    *   Se calcula la distancia coseno contra todos los vectores de noticias.
    *   Se aplica *Keyword Boosting* si "censo" aparece expl√≠citamente.
    *   Se filtran resultados con score < 0.12 (umbral de relevancia).
    *   Se toman los Top-3 resultados.
5.  **Generation (Generaci√≥n)**:
    *   Si Groq est√° activo: Se env√≠a el texto de las Top-3 noticias + la pregunta al LLM.
    *   Si Groq est√° inactivo: Se formatea una respuesta est√°tica con los res√∫menes.
6.  **Respuesta**: Se devuelve un JSON con el texto final (Markdown) y metadatos.

---

## 6. ‚öôÔ∏è Configuraci√≥n y Variables de Entorno

El sistema requiere un archivo `.env` en la ra√≠z:

```env
GROQ_API_KEY=gsk_...  # Tu API Key de Groq Cloud
```

### Par√°metros Ajustables (`config.py`)
*   `SECCIONES_CONFIG`: Aumentar el n√∫mero de p√°ginas aumenta la base de conocimiento pero retarda el inicio.
*   `EMBEDDING_MODEL`: Por defecto `paraphrase-multilingual-MiniLM-L12-v2`. Es el mejor balance velocidad/precisi√≥n para espa√±ol.

---

## 7. üö® Manejo de Errores y Limitaciones

*   **Fallos de Red**: El scraper reintenta 3 veces con *exponential backoff*. Si falla definitivamente, esa noticia se omite.
*   **Alucinaciones**: El prompt del sistema incluye instrucciones estrictas ("NO inventes datos") para minimizar invenciones, pero como todo LLM, no es infalible.
*   **Memoria**: Al ser una base de datos vectorial en memoria (RAM), el consumo crece linealmente con el n√∫mero de noticias. Para producci√≥n masiva se requerir√≠a una base de datos vectorial real (ej: Pinecone, ChromaDB).
